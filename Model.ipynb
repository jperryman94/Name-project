{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Great! Now that we have scraped our data, cleaned it, and prepared the features, we are ready to run a few different models to get the weights we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import unicodedata\n",
    "from random import randint\n",
    "import jellyfish\n",
    "import sys\n",
    "#sys.path.append(r'R:\\JoePriceResearch\\Python\\Anaconda3\\Lib\\site-packages')\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the function to break names into features.\n",
    "def VectorizeName(string, nparray=True):\n",
    "    '''\n",
    "    Takes a string and converts it into a numpy array of features. This assumes a name of length 3,\n",
    "    namely \"first middle last\". If you pass only one thing, it assumes a first name. Two things, first and last.\n",
    "    If you pass more than three things, it will take the first and the last words then combine all words in the\n",
    "    middle into one.\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    string  -  The name to be converted.\n",
    "    nparray -  Whether to return a list or an numpy array.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Either a list or a numpy array of features.\n",
    "    '''\n",
    "    # Ensure the string is lowercase.\n",
    "    string = string.lower()\n",
    "    \n",
    "    # Clean out any numbers.\n",
    "    string = re.sub('\\d', '', string)\n",
    "    string = re.sub('_', '', string)\n",
    "    \n",
    "    # Clean out accents, tildes, etc.\n",
    "    string = ''.join((c for c in unicodedata.normalize('NFD', u'{}'.format(string)) if unicodedata.category(c) != 'Mn'))\n",
    "    \n",
    "    # Clean out non-ascii characters.\n",
    "    string = string.encode('ascii', errors='ignore').decode()\n",
    "    \n",
    "    # Initialize the array.\n",
    "    vals = []\n",
    "    \n",
    "    # Get each value.\n",
    "    allwords = re.findall('\\w+', string)\n",
    "    if len(allwords) == 0:\n",
    "        allwords = [u'']\n",
    "    \n",
    "    # Assign first name.\n",
    "    first = allwords[0]\n",
    "    \n",
    "    # Assign last name if not the same as first.\n",
    "    if first != allwords[-1]:\n",
    "        last = allwords[-1]\n",
    "    else:\n",
    "        last = u''\n",
    "    \n",
    "    # Assign middle name, smashing all words in between first and last together.\n",
    "    middle = u''\n",
    "    for x in allwords[1:-1]:\n",
    "        middle = middle + x\n",
    "        \n",
    "    # Define a mapping for letters to numbers.\n",
    "    mapping = {'a' : 1, 'b' : 2, 'c' : 3, 'd' : 4, 'e' : 5, 'f' : 6, 'g' : 7, 'h' : 8, 'i' : 9, 'j' : 10, 'k' : 11, 'l' : 12,\n",
    "                  'm' : 13, 'n' : 14, 'o' : 15, 'p' : 16, 'q' : 17, 'r' : 18, 's' : 19, 't' : 20, 'u' : 21, 'v' : 22, 'w' : 23,\n",
    "                  'x' : 24, 'y' : 25, 'z' : 26}\n",
    "    \n",
    "    # Loop over the various names\n",
    "    for name in [first, middle, last]:\n",
    "        # If nothing for any of the names, return zeros.\n",
    "        #if len(name) == 0:\n",
    "        #    for x in range(34):\n",
    "        #        vals.append(0)\n",
    "        #    \n",
    "        #    continue\n",
    "        \n",
    "        # Get the length of the string.\n",
    "        vals.append(len(name))\n",
    "\n",
    "        # Get the number of each letter.\n",
    "        for x, y in enumerate('abcdefghijklmnopqrstuvwxyz'):\n",
    "            vals.append(name.count(y))\n",
    "\n",
    "        # Map the first three and last letters to numbers.\n",
    "        if len(name) >= 3:\n",
    "            vals.append(mapping[name[0]])\n",
    "            vals.append(mapping[name[1]])\n",
    "            vals.append(mapping[name[2]])\n",
    "            vals.append(mapping[name[-1]])\n",
    "        elif len(name) == 2:\n",
    "            vals.append(mapping[name[0]])\n",
    "            vals.append(mapping[name[1]])\n",
    "            vals.append(randint(1,26))\n",
    "            vals.append(mapping[name[-1]]) \n",
    "        elif len(name) == 1:\n",
    "            vals.append(mapping[name[0]])\n",
    "            vals.append(randint(1,26))\n",
    "            vals.append(randint(1,26))\n",
    "            vals.append(mapping[name[-1]])\n",
    "        else:\n",
    "            vals.append(randint(1,26))\n",
    "            vals.append(randint(1,26))\n",
    "            vals.append(randint(1,26))\n",
    "            vals.append(randint(1,26))\n",
    "            \n",
    "\n",
    "        # Get the soundex value.\n",
    "        sound = jellyfish.soundex(u'{}'.format(name))\n",
    "\n",
    "        # Convert the soundex value to a number.\n",
    "        if sound != '':\n",
    "            vals.append((mapping[sound[0].lower()]-1)*7*7*7 + int(sound[1])*7*7 + int(sound[2])*7 + (int(sound[3])+1))\n",
    "        else:\n",
    "            vals.append(randint(1,8576))\n",
    "        \n",
    "        # Initialize the number of vowels and consonants.\n",
    "        vowels = 0\n",
    "        const = 0\n",
    "\n",
    "        # Count the number of vowels and consonants.\n",
    "        for x in name:\n",
    "            if x in 'aeiouy':\n",
    "                vowels += 1\n",
    "            else:\n",
    "                const += 1\n",
    "\n",
    "        vals.append(vowels)\n",
    "        vals.append(const)\n",
    "        \n",
    "    # Get the number of words.\n",
    "    if allwords != [u'']:\n",
    "        vals.append(len(allwords))\n",
    "    else:\n",
    "        vals.append(0)\n",
    "\n",
    "    # Normalize the data.\n",
    "    #for x in range(len(vals)):\n",
    "    #    vals[x] = vals[x]/(10**(len(str(vals[x]))))\n",
    "    \n",
    "    # Return the values.\n",
    "    if nparray == True:\n",
    "        return np.array(vals)\n",
    "    else:\n",
    "        return list(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Normalize(vec1, vec2):\n",
    "    '''\n",
    "    Normalize each element of the vectors based on the maximum value at that spot in the row anywhere in either matrix.\n",
    "    Both parameters should be pandas columns of lists.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    vec1  -  First column of values.\n",
    "    vec2  -  Second column of values.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Two numpy arrays.\n",
    "    '''\n",
    "    # Zip the lists together correctly.\n",
    "    vec1 = list(zip(*vec1))\n",
    "    vec2 = list(zip(*vec2))\n",
    "    \n",
    "    # Get the maximum and divide the values.\n",
    "    for x in range(len(vec1)):\n",
    "        max_val = float(np.array((vec1[x] + vec2[x])).max())\n",
    "        vec1[x] = [y/max_val for y in vec1[x]]\n",
    "        vec2[x] = [y/max_val for y in vec2[x]]\n",
    "        \n",
    "    # Get the numpy arrays.\n",
    "    arr1 = [np.array(x) for x in list(zip(*vec1))]\n",
    "    arr2 = [np.array(x) for x in list(zip(*vec2))]\n",
    "    \n",
    "    # Return the arrays.\n",
    "    return arr1, arr2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we read in the data and fix the 'Match' column, we had a few values oddly coded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanne\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2717: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Read in the data.\n",
    "df = pd.read_csv(r'C:\\Users\\tanne\\Downloads\\names_final.csv')\n",
    "\n",
    "# Replace a few values.\n",
    "df['Match'] = df.Match.map({1 : 0, '0' : 1, 'match' : 1, 0 : 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the columns we need and make a train/test split so we can validate what we are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the target and training data, then delete df to save memory.\n",
    "target = df.Match.astype(int)\n",
    "train = df[df.columns[6:]]\n",
    "del df\n",
    "\n",
    "# Make a train/test split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we need to think about our model a little bit. We need to recover weights so that we can do the euclidean distances between the two sets of names, so linear regression is an obvious choice as the coefficients can be used easily as a type of weighting. Another is logit, which coefficients can also be used directly. We are also going to try random forest and gradient boosting, then we will naively use the feature importances as weights and see what happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will start with linear regression and save the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression.\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fit the model.\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Assign the coefficients.\n",
    "lr_coefs = lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will run logit, and in this case we can both save the coefficients and actually directly make predictions, so we will do that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE 0.04956716417910448\n",
      "Test MSE 0.04863636363636364\n",
      "Train Accuracy 0.9504328358208955\n",
      "Test Accuracy 0.9513636363636364\n"
     ]
    }
   ],
   "source": [
    "# Logit.\n",
    "lo = LogisticRegression()\n",
    "\n",
    "# Fit the model.\n",
    "lo = lo.fit(X_train,y_train)\n",
    "\n",
    "# Get the predictions for the model.\n",
    "train_predict = lo.predict(X_train)\n",
    "test_predict = lo.predict(X_test)\n",
    "\n",
    "# Print out the MSE and the accuracy.\n",
    "print(\"Train MSE {}\".format(mean_squared_error(y_train, train_predict)))\n",
    "print(\"Test MSE {}\".format(mean_squared_error(y_test, test_predict)))\n",
    "print(\"Train Accuracy {}\".format(accuracy_score(y_train, train_predict)))\n",
    "print(\"Test Accuracy {}\".format(accuracy_score(y_test, test_predict)))\n",
    "\n",
    "# Assign the coefficients.\n",
    "lo_coefs = lo.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, we actually did really well with our prediction accuracy on the test set at about 95 percent. Let's pick up with random forest now and see how we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE 0.0011492537313432835\n",
      "Test MSE 0.0155\n",
      "Train Accuracy 0.9988507462686567\n",
      "Test Accuracy 0.9845\n"
     ]
    }
   ],
   "source": [
    "# Random Forest.\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Fit the model.\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the predictions for the model.\n",
    "train_predict = rf.predict(X_train)\n",
    "test_predict = rf.predict(X_test)\n",
    "\n",
    "# Print out the MSE and the accuracy.\n",
    "print(\"Train MSE {}\".format(mean_squared_error(y_train, train_predict)))\n",
    "print(\"Test MSE {}\".format(mean_squared_error(y_test, test_predict)))\n",
    "print(\"Train Accuracy {}\".format(accuracy_score(y_train, train_predict)))\n",
    "print(\"Test Accuracy {}\".format(accuracy_score(y_test, test_predict)))\n",
    "\n",
    "# Get the feature importances.\n",
    "rf_coefs = rf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even better accuracy here, about 98 percent! Lastly we will try gradient boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE 0.02067910447761194\n",
      "Test MSE 0.020727272727272726\n",
      "Train Accuracy 0.9793208955223881\n",
      "Test Accuracy 0.9792727272727273\n"
     ]
    }
   ],
   "source": [
    "# XG Boost.\n",
    "xg = GradientBoostingClassifier()\n",
    "\n",
    "xg.fit(X_train, y_train)\n",
    "\n",
    "train2_predict = xg.predict(X_train)\n",
    "test2_predict = xg.predict(X_test)\n",
    "\n",
    "print(\"Train MSE {}\".format(mean_squared_error(y_train, train2_predict)))\n",
    "print(\"Test MSE {}\".format(mean_squared_error(y_test, test2_predict)))\n",
    "print(\"Train Accuracy {}\".format(accuracy_score(y_train, train2_predict)))\n",
    "print(\"Test Accuracy {}\".format(accuracy_score(y_test, test2_predict)))\n",
    "\n",
    "# Get the feature importances.\n",
    "xg_coefs = xg.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not quite as good as the random forest, but still a solid 97 percent accuracy.\n",
    "\n",
    "Now we are going to run an independent validation of our models using the saved weights. Our motivation here is that pairwise comparisons between names are often very slow, so if we can get the right weighted euclidean distance then we can use matrix multiplication to make the pairwise comparisons, which tends to be faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the original data to recover the vectors and prepare it using the same functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validation.\n",
    "# Read in the data.\n",
    "df = pd.read_csv(r'C:\\Users\\tanne\\Downloads\\true_names.csv', encoding='utf-8', nrows=100000)\n",
    "false = pd.read_csv(r'C:\\Users\\tanne\\Downloads\\false_names2.csv', encoding='utf-8', nrows=100000)\n",
    "\n",
    "# Keep the correct columns for false and rename.\n",
    "false = false[['fsid', 'full1', 'first1', 'mid1', 'last1', 'full2', 'first2', 'mid2', 'last2', 'match']]\n",
    "false.columns = ['fsid', 'Full1', 'First1', 'Mid1', 'Last1', 'Full2', 'First2', 'Mid2', 'Last2', 'Match']\n",
    "\n",
    "# Append the data together.\n",
    "df = df.append(false, ignore_index=True)\n",
    "\n",
    "# Replace a few values.\n",
    "df['Match'] = df.Match.map({1 : 0, '0' : 1, 'match' : 1, 0 : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get rid of missing values.\n",
    "for x in ['Full1', 'Full2', 'First1', 'First2', 'Mid1', 'Mid2', 'Last1', 'Last2']:\n",
    "    df[x] = df[x].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the names.\n",
    "df['Full1vec'] = df.Full1.apply(VectorizeName)\n",
    "df['Full2vec'] = df.Full2.apply(VectorizeName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Normalize the name vectors.\n",
    "df['Full1vec'], df['Full2vec'] = Normalize(df['Full1vec'], df['Full2vec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will make weighted versions of the vectors using each of the different model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight using the linear regression weights.\n",
    "df['lr1'] = df.Full1vec * np.array(lr_coefs)\n",
    "df['lr2'] = df.Full2vec * np.array(lr_coefs)\n",
    "\n",
    "# Weight using the logit weights\n",
    "df['lo1'] = df.Full1vec * np.array(lo_coefs)\n",
    "df['lo2'] = df.Full2vec * np.array(lo_coefs)\n",
    "\n",
    "# Weight using the random forest weights\n",
    "df['rf1'] = df.Full1vec * np.array(rf_coefs)\n",
    "df['rf2'] = df.Full2vec * np.array(rf_coefs)\n",
    "\n",
    "# Weight using the xg boost weights\n",
    "df['xg1'] = df.Full1vec * np.array(xg_coefs)\n",
    "df['xg2'] = df.Full2vec * np.array(xg_coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we get the euclidean distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the euclidean distances.\n",
    "df['score'] = df.apply(lambda x: np.linalg.norm(x.Full1vec - x.Full2vec), axis=1)\n",
    "df['scorelr'] = df.apply(lambda x: np.linalg.norm(x.lr1 - x.lr2), axis=1)\n",
    "df['scorelo'] = df.apply(lambda x: np.linalg.norm(x.lo1 - x.lo2), axis=1)\n",
    "df['scorerf'] = df.apply(lambda x: np.linalg.norm(x.rf1 - x.rf2), axis=1)\n",
    "df['scorexg'] = df.apply(lambda x: np.linalg.norm(x.xg1 - x.xg2), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find a cutoff for the distances we just heuristically look at the summary statistics for each set of scores and choose a cutoff that reasonably splits the matches from the non-matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted Non-Matches:\n",
      " count    100000.000000\n",
      "mean          1.199137\n",
      "std           0.268797\n",
      "min           0.086003\n",
      "25%           1.015872\n",
      "50%           1.197606\n",
      "75%           1.381173\n",
      "max           2.567467\n",
      "Name: score, dtype: float64\n",
      "Unweighted Matches:\n",
      " count    100000.000000\n",
      "mean          1.171367\n",
      "std           0.427775\n",
      "min           0.000000\n",
      "25%           0.895745\n",
      "50%           1.144085\n",
      "75%           1.449079\n",
      "max           3.554618\n",
      "Name: score, dtype: float64\n",
      "Linear Regression Non-Matches:\n",
      " count    100000.000000\n",
      "mean          0.764453\n",
      "std           0.459306\n",
      "min           0.005177\n",
      "25%           0.546967\n",
      "50%           0.665241\n",
      "75%           0.839765\n",
      "max          15.659578\n",
      "Name: scorelr, dtype: float64\n",
      "Linear Regression Matches:\n",
      " count    100000.000000\n",
      "mean          3.847041\n",
      "std           2.831711\n",
      "min           0.000000\n",
      "25%           1.447394\n",
      "50%           4.146727\n",
      "75%           6.221056\n",
      "max          42.294875\n",
      "Name: scorelr, dtype: float64\n",
      "Logit Non-Matches:\n",
      " count    100000.000000\n",
      "mean          5.551618\n",
      "std           1.668172\n",
      "min           0.057655\n",
      "25%           4.470156\n",
      "50%           5.362045\n",
      "75%           6.441471\n",
      "max          20.794816\n",
      "Name: scorelo, dtype: float64\n",
      "Logit Matches:\n",
      " count    100000.000000\n",
      "mean          7.752388\n",
      "std           3.666784\n",
      "min           0.000000\n",
      "25%           5.222269\n",
      "50%           7.839845\n",
      "75%          10.106722\n",
      "max          37.411724\n",
      "Name: scorelo, dtype: float64\n",
      "Random Forest Non-Matches:\n",
      " count    100000.000000\n",
      "mean          0.028643\n",
      "std           0.016915\n",
      "min           0.000777\n",
      "25%           0.015667\n",
      "50%           0.024082\n",
      "75%           0.038664\n",
      "max           0.135803\n",
      "Name: scorerf, dtype: float64\n",
      "Random Forest Matches:\n",
      " count    100000.000000\n",
      "mean          0.033569\n",
      "std           0.023328\n",
      "min           0.000000\n",
      "25%           0.014517\n",
      "50%           0.030174\n",
      "75%           0.044584\n",
      "max           0.236046\n",
      "Name: scorerf, dtype: float64\n",
      "XG Boost Non-Matches:\n",
      " count    100000.000000\n",
      "mean          0.027071\n",
      "std           0.009620\n",
      "min           0.002521\n",
      "25%           0.020520\n",
      "50%           0.026008\n",
      "75%           0.031962\n",
      "max           0.121340\n",
      "Name: scorexg, dtype: float64\n",
      "XG Boost Matches:\n",
      " count    100000.000000\n",
      "mean          0.035618\n",
      "std           0.020087\n",
      "min           0.000000\n",
      "25%           0.021635\n",
      "50%           0.033634\n",
      "75%           0.045880\n",
      "max           0.240370\n",
      "Name: scorexg, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print out the summary statistics.\n",
    "print('Unweighted Non-Matches:\\n', df.score.loc[df.Match == 1].describe())\n",
    "print('Unweighted Matches:\\n', df.score.loc[df.Match == 0].describe())\n",
    "\n",
    "print('Linear Regression Non-Matches:\\n', df.scorelr.loc[df.Match == 1].describe())\n",
    "print('Linear Regression Matches:\\n', df.scorelr.loc[df.Match == 0].describe())\n",
    "\n",
    "print('Logit Non-Matches:\\n', df.scorelo.loc[df.Match == 1].describe())\n",
    "print('Logit Matches:\\n', df.scorelo.loc[df.Match == 0].describe())\n",
    "\n",
    "print('Random Forest Non-Matches:\\n', df.scorerf.loc[df.Match == 1].describe())\n",
    "print('Random Forest Matches:\\n', df.scorerf.loc[df.Match == 0].describe())\n",
    "\n",
    "print('XG Boost Non-Matches:\\n', df.scorexg.loc[df.Match == 1].describe())\n",
    "print('XG Boost Matches:\\n', df.scorexg.loc[df.Match == 0].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are our cutoffs. They are a little odd, the math did not quite work out as anticipated, but as you will see below we ended up with a reasonable accuracy for the linear regression weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "df['un_pred'] = (df.score < 1.5)\n",
    "df['lr_pred'] = (df.scorelr < 1.4) & (df.scorelr != 0.0)\n",
    "df['lo_pred'] = (df.scorelo < 7.3) & (df.scorelo != 0.0)\n",
    "df['rf_pred'] = (df.scorerf < 0.03) & (df.scorerf != 0.0)\n",
    "df['xg_pred'] = (df.scorexg < 0.03) & (df.scorexg != 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted Accuracy: 0.544545\n",
      "Linear Regression Accuracy: 0.874245\n",
      "Logit Accuracy: 0.725355\n",
      "Random Forest Accuracy: 0.563765\n",
      "XG Boost Accuracy: 0.642005\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy.\n",
    "print('Unweighted Accuracy:', (df.un_pred == df.Match).sum()/len(df))\n",
    "print('Linear Regression Accuracy:', (df.lr_pred == df.Match).sum()/len(df))\n",
    "print('Logit Accuracy:', (df.lo_pred == df.Match).sum()/len(df))\n",
    "print('Random Forest Accuracy:', (df.rf_pred == df.Match).sum()/len(df))\n",
    "print('XG Boost Accuracy:', (df.xg_pred == df.Match).sum()/len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So there is still quite a bit of work to do before this would be useful in functionally matching names, but we made strides to another name matching method that might have some value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
